{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bace4eb8-1fce-40d1-a070-cd7eae65f1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm  \n",
    "from sklearn.decomposition import PCA\n",
    "import umap\n",
    "import umap.plot\n",
    "import plotly.graph_objs as go \n",
    "import plotly.io as pio \n",
    "pio.renderers.default ='iframe'\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a91ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist_dataset import MNISTDataset \n",
    "#load dataset \n",
    "data = pd.read_csv('data/train.csv')\n",
    "val_count =1000\n",
    "\n",
    "#common transformation\n",
    "default_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(0.5,0.5)\n",
    "])\n",
    "\n",
    "#split the train to val and train\n",
    "dataset = MNISTDataset(data.iloc[:-val_count], default_transform)\n",
    "val_dataset = MNISTDataset(data.iloc[-val_count:], default_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8a3df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup Dataloaders with pytorch dataloaders\n",
    "trainloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size = 16,\n",
    "    shuffle =True,\n",
    "    pin_memory = True, # for faster data transfer speed btn CPU and GPU, but will consume more system memory\n",
    "    num_workers = 2,\n",
    "    prefetch_factor = 100,#to specify how many batches should be prefetched(loaded into memory[increased memory usage tho]) asynchronously in advance.\n",
    "\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de91ca38-4641-43fc-a054-9af4e0e45918",
   "metadata": {},
   "source": [
    "# visualizing Datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431a76d4-b95e-49ca-a943-7d9dd320ed23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images, title =''):\n",
    "    num_images = len(images)\n",
    "    fig,axes = plt.subplots(1, num_images,figsize=(9,3))\n",
    "    for i in range(num_images):\n",
    "        img = np.squeeze(images[i])\n",
    "        axes[i].imshow(img,cmap='gray')\n",
    "        axes[i].axis('off')\n",
    "    fig.suptitle(title)\n",
    "    plt.show()\n",
    "    \n",
    "for batch_idx, (anchor_images, contrastive_images, distances, labels) in enumerate(trainloader):\n",
    "    #converting tensors to numpy, numpy is easy to muniplate and display with matplotlib\n",
    "    anchor_images = anchor_images.numpy()\n",
    "    contrastive_images = contrastive_images.numpy()\n",
    "    labels = labels.numpy()\n",
    "\n",
    "    #display some imgages from batch\n",
    "    show_images(anchor_images[:4], title = 'Anchor Images')\n",
    "    show_images(contrastive_images[:4], title = '+/- Example Images')\n",
    "    #break after displaying from one batch for demostration \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68115e5-2935-48f5-a968-12f4fe679b70",
   "metadata": {},
   "source": [
    "# lets build Neural Network\n",
    "-  Define a neural network architecture with two convolution layers and two fully connected layers\n",
    "- Input to the network is an MNIST image and Output is a 64 dimensional representation. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f725e1e-0423-47f8-b173-8ab9d05296eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Network import Network, ContrastiveLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4f49e1-4752-453a-8522-4ee463060cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network()\n",
    "\n",
    "device= \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "    device= \"mps\"\n",
    "\n",
    "net = net.to(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f8b27f-d130-4697-a2cf-a1efe0de0130",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(net.parameters(), lr = 3e-4)\n",
    "loss_function = ContrastiveLoss()\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1074f81-4ec1-4d6f-90db-51f9425197f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "checkpoint_dir ='checkpoints/'\n",
    "\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd524c75-d2b2-432f-a699-4612bfa7c3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save_checkpoint(net, epoch, checkpoint_dir='checkpoints'):\n",
    "#     os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "#     checkpoint_path = os.path.join(checkpoint_dir, f'model_epoch_{epoch}.pt')\n",
    "#     torch.save(net.state_dict(), checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d6d592-6e15-4163-bb9e-a7a4a56b9752",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Train_model(epoch_count=1):\n",
    "    net = Network()\n",
    "    net = net.to(device)\n",
    "    lrs = []\n",
    "    losses = []\n",
    "\n",
    "    for epoch in range(epoch_count):\n",
    "        epoch_loss = 0\n",
    "        batches = 0\n",
    "        print('epoch-',epoch)\n",
    "        for param_group in optimizer.param_groups:\n",
    "            lrs.append(param_group['lr'])\n",
    "        \n",
    "        #lrs.append(optimizer.param_group[0]['lr'])\n",
    "        print('learning rate',lrs[-1])\n",
    "\n",
    "        for anchor, contrastive, distance, label in tqdm(trainloader):\n",
    "            \n",
    "            # Ensure data is in the correct shape\n",
    "            assert anchor.shape[1] == 1, f\"Expected anchor channels to be 1, but got {anchor.shape[1]}\"\n",
    "            assert contrastive.shape[1] == 1, f\"Expected contrastive channels to be 1, but got {contrastive.shape[1]}\"\n",
    "\n",
    "            batches +=1\n",
    "            optimizer.zero_grad()\n",
    "            anchor_out = anchor.to(device, dtype=torch.float32)\n",
    "            contrastive_out = contrastive.to(device, dtype=torch.float32)\n",
    "            distance = distance.to(torch.float32).to(device)\n",
    "\n",
    "            anchor_out = net(anchor_out)\n",
    "            contrastive_out = net(contrastive_out)\n",
    "            \n",
    "            loss = loss_function(anchor_out, contrastive_out, distance)\n",
    "            epoch_loss += loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        losses.append(epoch_loss.cpu().detach().numpy()/ batches)\n",
    "        scheduler.step()\n",
    "        print('epoch_loss', losses[-1])\n",
    "\n",
    "        #save checkpoint\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'model_epoch{epoch}.pt')\n",
    "        torch.save(net.state_dict(), checkpoint_path)\n",
    "        \n",
    "    return{\n",
    "        \"net\": net,\n",
    "        \"losses\":losses\n",
    "    }\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ed3fde-5a90-40fc-997e-a3fa139ae9d2",
   "metadata": {},
   "source": [
    "# load from backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2782299-3a0c-457d-b580-c484b9cf82b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_model_from_checkpoint():\n",
    "#     checkpoint = torch.load('checkpoints/model_epoch_99.pt')\n",
    "\n",
    "#     net = Network()\n",
    "#     net.load_state_dict(checkpoint)\n",
    "#     net.eval()\n",
    "\n",
    "#     return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45e31e5-e4b4-4397-8243-abbe17562edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def save_checkpoint(net, epoch, checkpoint_dir='checkpoints'):\n",
    "#     os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "#     checkpoint_path = os.path.join(checkpoint_dir, f'model_epoch_{epoch}.pt')\n",
    "#     torch.save(net.state_dict(), checkpoint_path)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92200c38-6f17-4e5c-be23-d54d1507faa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_latest_checkpoint(checkpoint_dir='checkpoints'):\n",
    "    # List all checkpoint files\n",
    "    checkpoint_files = [f for f in os.listdir(checkpoint_dir) if f.startswith('model_epoch') and f.endswith('.pt')]\n",
    "    \n",
    "    # Extract epoch numbers\n",
    "    epochs = [int(re.findall(r'\\d+', f)[0]) for f in checkpoint_files]\n",
    "    \n",
    "    # Find the latest epoch\n",
    "    latest_epoch = max(epochs)\n",
    "    latest_checkpoint_path = os.path.join(checkpoint_dir, f'model_epoch_{latest_epoch}.pt')\n",
    "    \n",
    "    # Load the latest checkpoint\n",
    "    checkpoint = torch.load(latest_checkpoint_path)\n",
    "    net = Network()\n",
    "    net.load_state_dict(checkpoint)\n",
    "    net.eval()\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4d4586-17dc-4c93-a313-c0ed577cca61",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = True\n",
    "checkpoint_dir = 'checkpoints'\n",
    "\n",
    "if train:\n",
    "    training_result = Train_model()\n",
    "    model = training_result[\"net\"]\n",
    "else:\n",
    "    model = load_latest_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ce5e0f-b759-491b-9ca3-0a19f9b82d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "if train:\n",
    "    plt.plot(training_result[losses])\n",
    "    plt.show()\n",
    "else:\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
