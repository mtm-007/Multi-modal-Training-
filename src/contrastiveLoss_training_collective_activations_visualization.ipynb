{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bace4eb8-1fce-40d1-a070-cd7eae65f1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm  \n",
    "from sklearn.decomposition import PCA\n",
    "import umap\n",
    "import math\n",
    "import io\n",
    "import umap.plot\n",
    "import plotly.graph_objs as go \n",
    "import plotly.io as pio \n",
    "pio.renderers.default ='iframe'\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from PIL import Image  # Add this import statement\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import math,os,sys\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a91ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist_dataset import MNISTDataset \n",
    "#load dataset \n",
    "data = pd.read_csv('../data/train.csv')\n",
    "data = data[:1000]\n",
    "#temporarly trying to overfit with less data\n",
    "val_count =200\n",
    "\n",
    "#common transformation\n",
    "default_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(0.5,0.5)\n",
    "])\n",
    "\n",
    "#split the train to val and train\n",
    "dataset = MNISTDataset(data.iloc[:-val_count], default_transform)\n",
    "val_dataset = MNISTDataset(data.iloc[-val_count:], default_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8a3df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup Dataloaders with pytorch dataloaders\n",
    "trainloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size = 128*2,\n",
    "    shuffle =True,\n",
    "    #pin_memory = True, # for faster data transfer speed btn CPU and GPU, but will consume more system memory\n",
    "    num_workers = 2,\n",
    "    #prefetch_factor = 100,#to specify how many batches should be prefetched(loaded into memory[increased memory usage tho]) asynchronously in advance.\n",
    "\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de91ca38-4641-43fc-a054-9af4e0e45918",
   "metadata": {},
   "source": [
    "# visualizing Datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431a76d4-b95e-49ca-a943-7d9dd320ed23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images, title =''):\n",
    "    num_images = len(images)\n",
    "    fig,axes = plt.subplots(1, num_images,figsize=(9,3))\n",
    "    for i in range(num_images):\n",
    "        img = np.squeeze(images[i])\n",
    "        axes[i].imshow(img,cmap='gray')\n",
    "        axes[i].axis('off')\n",
    "    fig.suptitle(title)\n",
    "    plt.show()\n",
    "    \n",
    "for batch_idx, (anchor_images, contrastive_images, distances, labels) in enumerate(trainloader):\n",
    "    #converting tensors to numpy, numpy is easy to muniplate and display with matplotlib\n",
    "    anchor_images = anchor_images.numpy()\n",
    "    contrastive_images = contrastive_images.numpy()\n",
    "    labels = labels.numpy()\n",
    "\n",
    "    #display some imgages from batch\n",
    "    show_images(anchor_images[:4], title = 'Anchor Images')\n",
    "    show_images(contrastive_images[:4], title = '+/- Example Images')\n",
    "    #break after displaying from one batch for demostration \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68115e5-2935-48f5-a968-12f4fe679b70",
   "metadata": {},
   "source": [
    "# lets build Neural Network\n",
    "-  Define a neural network architecture with two convolution layers and two fully connected layers\n",
    "- Input to the network is an MNIST image and Output is a 64 dimensional representation. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f725e1e-0423-47f8-b173-8ab9d05296eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Network import Network,Network_t ,ContrastiveLoss_with_margin\n",
    "from utils import init_weights, init_weights_for_gelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4f49e1-4752-453a-8522-4ee463060cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network()\n",
    "\n",
    "device= \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "    device= \"mps\"\n",
    "\n",
    "#device= \"cpu\" #overide device for overfitting a very small data batch\n",
    "net = net.to(device)\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4213cc3d-bbd1-4d3c-8189-9c0581e0334d",
   "metadata": {},
   "source": [
    "### weight initialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f192860c-848f-422a-b0c6-fdff6d3e8ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau,CosineAnnealingLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f8b27f-d130-4697-a2cf-a1efe0de0130",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_count=10\n",
    "optimizer = torch.optim.AdamW(net.parameters(), lr = 0.01,weight_decay=1e-5)\n",
    "#optimizer = torch.optim.AdamW(net.parameters())\n",
    "loss_function = ContrastiveLoss_with_margin()\n",
    "#scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.3)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=epoch_count, eta_min=1e-6)\n",
    "#scheduler reduces plateau loss\n",
    "#scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1074f81-4ec1-4d6f-90db-51f9425197f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "checkpoint_dir ='checkpoints/'\n",
    "\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bc60b6-15c5-4a88-b72c-5a6c92e24872",
   "metadata": {},
   "source": [
    "# take two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e27edf-535f-4bcd-83b3-7f7bab5b1b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import random\n",
    "\n",
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"Contrastive_learning\",\n",
    "\n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"architecture\": \"CNN with contrastive Loss\",\n",
    "    \"dataset\": \"Mnist -dataset\",\n",
    "    \"epochs\": 10,\n",
    "    \"batch size\" : 256,\n",
    "    }\n",
    ")\n",
    "\n",
    "activations_list = []\n",
    "gradients = []\n",
    "\n",
    "def Train_model(epoch_count=10):\n",
    "    net = Network()\n",
    "    #The log=\"all\" parameter tells wandb to log gradients and parameters, and \n",
    "    #log_freq=64 means it will log every 64 batches.\n",
    "    wandb.watch(net, log=\"all\", log_freq=64) \n",
    "    net.apply(init_weights_for_gelu)\n",
    "    net = net.to(device)\n",
    "    lrs = []\n",
    "    losses = []\n",
    "    activations_dict = defaultdict(lambda: {'mean': [], 'var': [], 'neg_ratio': []})\n",
    "    \n",
    "    def get_activation_stats(name):\n",
    "        def hook(model, input, output):\n",
    "            mean = output.detach().mean().item()\n",
    "            var = output.detach().var().item()\n",
    "            neg_ratio = (output.detach() < 0).float().mean().item()\n",
    "            activations_dict[name]['mean'].append(mean)\n",
    "            activations_dict[name]['var'].append(var)\n",
    "            activations_dict[name]['neg_ratio'].append(neg_ratio)\n",
    "            # this was not printing coz of leakyReLU wasnt correctly called(was only nn.ReLU)\n",
    "            #print(f'Hook called for {name}: mean={mean}, var={var}, neg_ratio={neg_ratio}')\n",
    "        return hook   \n",
    "    \n",
    "    # Register hooks for GELU layers (or whatever activation you're using)\n",
    "    for name, layer in net.named_modules():\n",
    "        if isinstance(layer, nn.LeakyReLU):\n",
    "            layer.register_forward_hook(get_activation_stats(name))\n",
    "            #print(f'Registered hook for layer: {name}') #-----debugging print worked\n",
    "            \n",
    "    def capture_gradient(name):\n",
    "        def hook(module, grad_input, grad_output):\n",
    "            gradients.append((name, grad_output[0].detach()))\n",
    "        return hook\n",
    "        \n",
    "    for epoch in range(epoch_count):\n",
    "        epoch_loss = 0\n",
    "        batches = 0\n",
    "        \n",
    "        print('epoch-', epoch) \n",
    "        wandb.log({'epoch': epoch})\n",
    "\n",
    "        for param_group in optimizer.param_groups:\n",
    "            lrs.append(param_group['lr'])\n",
    "        \n",
    "        print('learning rate', lrs[-1])\n",
    "        wandb.log({'learning rate -':lrs[-1]})\n",
    "        \n",
    "        for anchor, contrastive, distance, label in tqdm(trainloader):\n",
    "            # assert anchor.shape[1] == 1, f\"Expected anchor channels to be 1, but got {anchor.shape[1]}\"\n",
    "            # assert contrastive.shape[1] == 1, f\"Expected contrastive channels to be 1, but got {contrastive.shape[1]}\"\n",
    "            batches += 1\n",
    "            optimizer.zero_grad()\n",
    "            anchor_out = anchor.to(device, dtype=torch.float32)\n",
    "            contrastive_out = contrastive.to(device, dtype=torch.float32)\n",
    "            distance = distance.to(torch.float32).to(device)\n",
    "            anchor_out = net(anchor_out)\n",
    "            contrastive_out = net(contrastive_out)\n",
    "            \n",
    "            loss = loss_function(anchor_out, contrastive_out, distance)\n",
    "            epoch_loss += loss\n",
    "            loss.backward()\n",
    "            norm = torch.nn.utils.clip_grad_norm_(net.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "        \n",
    "        #avg_loss = epoch_loss / batches\n",
    "        \n",
    "        # Debugging: Print activation statistics\n",
    "        #print(f'Activations after epoch {epoch}:', {k: {stat: v[stat][-batches:] for stat in v} for k, v in activations_dict.items()})\n",
    "        \n",
    "        activations_list.append({k: {stat: v[stat][-batches:] for stat in v} for k, v in activations_dict.items()})\n",
    "        losses.append(epoch_loss.cpu().detach().numpy() / batches)\n",
    "        \n",
    "        print('epoch_loss', losses[-1])\n",
    "        wandb.log({'epoch_loss -': losses[-1]})\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'model_epoch{epoch}.pt')\n",
    "        torch.save(net.state_dict(), checkpoint_path)\n",
    "\n",
    "    # Debugging: Print entire activations list\n",
    "    #print('Final activations_list:', activations_list)\n",
    "\n",
    "    plot_activation_stats(activations_list)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(lrs, losses)\n",
    "    plt.xlabel('Learning Rate')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Learning Rate vs. Loss')\n",
    "    plt.show()\n",
    "\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    buf.seek(0)\n",
    "    \n",
    "    # Convert BytesIO to PIL Image\n",
    "    image1 = Image.open(buf)\n",
    "    wandb.log({\"Learning Rate vs. Loss\": wandb.Image(image1)})\n",
    "\n",
    "    return {\n",
    "        \"net\": net,\n",
    "        \"losses\": losses,\n",
    "        \"activations\": activations_list\n",
    "    }\n",
    "\n",
    "def plot_activation_stats(activations_list):\n",
    "    if not activations_list:\n",
    "        print(\"No activation data to plot.\")\n",
    "        wandb.log({'message':'No activation data to plot'})\n",
    "        return\n",
    "\n",
    "    for layer_name in activations_list[0].keys():\n",
    "        means = [epoch[layer_name]['mean'] for epoch in activations_list]\n",
    "        vars = [epoch[layer_name]['var'] for epoch in activations_list]\n",
    "        neg_ratios = [epoch[layer_name]['neg_ratio'] for epoch in activations_list]\n",
    "\n",
    "        # logging this stat only on wandb \n",
    "        #print(f'Plotting data for layer: {layer_name}')\n",
    "        wandb.log({'Plotting data for layer':layer_name}) # logging this stat only on wandb \n",
    "        #print(f'Means: {means}')\n",
    "        wandb.log({'Means': means})\n",
    "        #print(f'Variances: {vars}')\n",
    "        wandb.log({'Variances': vars})\n",
    "        #print(f'Negative Ratios: {neg_ratios}')\n",
    "        wandb.log({'Negative Ratios':neg_ratios})\n",
    "\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.subplot(131)\n",
    "        plt.plot(means)\n",
    "        plt.title(f'{layer_name} - Mean Activation')\n",
    "        plt.xlabel('Batch')\n",
    "        plt.ylabel('Mean')\n",
    "        \n",
    "        plt.subplot(132)\n",
    "        plt.plot(vars)\n",
    "        plt.title(f'{layer_name} - Activation Variance')\n",
    "        plt.xlabel('Batch')\n",
    "        plt.ylabel('Variance')\n",
    "\n",
    "        plt.subplot(133)\n",
    "        plt.plot(neg_ratios)\n",
    "        plt.title(f'{layer_name} - Negative Activation Ratio')\n",
    "        plt.xlabel('Batch')\n",
    "        plt.ylabel('Ratio')\n",
    "         \n",
    "        plt.tight_layout()\n",
    "        \n",
    "\n",
    "        # Save the plot to a buffer\n",
    "        buf = io.BytesIO()\n",
    "        plt.savefig(buf, format='png')\n",
    "        buf.seek(0)\n",
    "\n",
    "        # Convert BytesIO to PIL Image\n",
    "        image = Image.open(buf)\n",
    "\n",
    "        # Log the plot to Weights and Biases\n",
    "        wandb.log({f'{layer_name} activations': wandb.Image(image)})\n",
    "        plt.show() # this should be after wandb log \n",
    "\n",
    "        plt.close()  # Close the figure to free up memory\n",
    "        buf.close()\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# Train_model(epoch_count=10)\n",
    "checkpoint_dir = 'checkpoints'\n",
    "train =True\n",
    "\n",
    "if train:\n",
    "    training_result = Train_model()\n",
    "    model = training_result[\"net\"]\n",
    "else:\n",
    "    model = load_latest_checkpoint(checkpoint_dir)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4543a9cb-ce53-4456-9ff2-c3cc17e7fe25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this prints the class layers modules \n",
    "def print_layer_types(net):\n",
    "    for name, layer in net.named_modules():\n",
    "        print(f'{name}: {type(layer)}')\n",
    "\n",
    "# Example usage:\n",
    "net = Network()\n",
    "print_layer_types(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04acfe13-083f-472b-a6ff-186e2306a39a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b2a8f8-b840-49ec-9080-34e1256375db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e2289ea-9ee1-4b07-8a69-f526cc7dd56d",
   "metadata": {},
   "source": [
    "# Visualize activations after training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68229292-542f-4903-873f-0684ff739ae9",
   "metadata": {},
   "source": [
    "## Debugging sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63966726-1f57-4777-9373-7e90bf3f6368",
   "metadata": {},
   "source": [
    "# initial loss estimation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf60c3d3-f656-43d4-aafd-b4e10c2bffca",
   "metadata": {},
   "outputs": [],
   "source": [
    "margin = 0.5\n",
    "\n",
    "# Expected loss for similar pairs\n",
    "expected_similar_loss = 1.0  # As (1 - score)^2 with score ≈ 0\n",
    "\n",
    "# Expected loss for dissimilar pairs\n",
    "expected_dissimilar_loss = margin ** 2  # As (score - margin)^2 with score ≈ 0\n",
    "\n",
    "# Average the losses\n",
    "initial_loss = (expected_similar_loss + expected_dissimilar_loss) / 2\n",
    "\n",
    "print(f'Expected initial contrastive loss (cosine similarity with margin): {initial_loss}')\n",
    "\n",
    "#--- \"Expected initial contrastive loss (cosine similarity with margin): 0.625\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92b5416-0f67-4316-bba7-26bfb661f462",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26757820-6cb5-4d3f-842f-9047660a6ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "if training_result[\"activations\"]:\n",
    "    print(list(training_result[\"activations\"][0].keys()))\n",
    "    for key in training_result[\"activations\"][0].keys():\n",
    "        print(f\"{key}: {training_result['activations'][0][key].keys()}\")\n",
    "else:\n",
    "    print(\"Activations list is empty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a473960-cb0a-4069-bed9-75a274ff81da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_activation_stats(activations_list):\n",
    "    print(f\"Number of epochs: {len(activations_list)}\")\n",
    "    \n",
    "    if not activations_list:\n",
    "        print(\"Activations list is empty\")\n",
    "        return\n",
    "\n",
    "    for layer_name in activations_list[0].keys():\n",
    "        print(f\"Plotting for layer: {layer_name}\")\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        \n",
    "        for i, stat in enumerate(['mean', 'var', 'neg_ratio'], 1):\n",
    "            plt.subplot(1, 3, i)\n",
    "            values = [epoch[layer_name][stat] for epoch in activations_list]\n",
    "            print(f\"{stat} values: {values[:5]}...\")  # Print first 5 values\n",
    "            \n",
    "            if not values:\n",
    "                print(f\"No {stat} values for {layer_name}\")\n",
    "                continue\n",
    "            \n",
    "            plt.plot(values)\n",
    "            plt.title(f'{layer_name} - {stat.capitalize()}')\n",
    "            plt.xlabel('Batch')\n",
    "            plt.ylabel(stat.capitalize())\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "plot_activation_stats(training_result[\"activations\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b9972a-d1e1-4c2c-b695-61c243ab1d5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afb3d41-f611-45ea-a396-1f6f2669058c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9b5a37-5c87-4d21-b10f-686b4a4653c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394bc777-e9b1-4ae0-adc6-412a6e9e439d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb0c019-b1d4-4757-bf83-dc64656a8048",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 4))\n",
    "legends = []\n",
    "\n",
    "# Assuming activations_list is a list of dictionaries\n",
    "for epoch, epoch_activations in enumerate(activations_list):\n",
    "    print(activations_list)\n",
    "    for i, (name, tensors) in enumerate(epoch_activations.items()):\n",
    "        # Combine all tensors for this layer across batches\n",
    "        all_tensors = torch.cat(tensors, dim=0)\n",
    "\n",
    "        # Calculate metrics\n",
    "        zero_percentage = (all_tensors == 0).float().mean().item() * 100\n",
    "        mean_value = all_tensors.mean().item()\n",
    "        std_value = all_tensors.std().item()\n",
    "        sparsity = (all_tensors != 0).float().mean().item() * 100\n",
    "        variance = all_tensors.var().item()\n",
    "    \n",
    "        print(f'Epoch {epoch}, Layer {i} ({name}): mean: {mean_value:+.2f}, std: {std_value:.2f}, zeros: {zero_percentage:.2f}%, sparsity: {sparsity:.2f}%, variance: {variance:.2f}')\n",
    "     \n",
    "        # Compute the histogram using numpy\n",
    "        hist, bin_edges = np.histogram(all_tensors.cpu().numpy().flatten(), bins=50, range=(-2, 2))\n",
    "        \n",
    "        # Plot the histogram\n",
    "        plt.plot(bin_edges[:-1], hist)\n",
    "        legends.append(f'{name} (Epoch {epoch})')\n",
    "\n",
    "plt.legend(legends)\n",
    "plt.title('Activation Distributions')\n",
    "plt.xlabel('Activation Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2873a894-d511-4641-96bc-a1684895271f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'activations' is a list of (name, tensor) tuples\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "legends = []\n",
    "for name, t in activations:\n",
    "    # Calculate metrics\n",
    "    zero_percentage = (t == 0).float().mean() * 100\n",
    "    mean_value = t.mean().item()\n",
    "    std_value = t.std().item()\n",
    "    sparsity = (t != 0).float().mean() * 100\n",
    "    variance = t.var().item()\n",
    "\n",
    "    print(f'{name}: mean: {mean_value:+.2f}, std: {std_value:.2f}, zeros: {zero_percentage:.2f}%, sparsity: {sparsity:.2f}%, variance: {variance:.2f}')\n",
    "    \n",
    "    hy, hx = torch.histogram(t, density=True)\n",
    "    plt.plot(hx[:-1].detach().cpu(), hy.detach().cpu())\n",
    "    legends.append(name)\n",
    "\n",
    "plt.legend(legends[:3])\n",
    "plt.title('Activation Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ba4608-8d3f-449a-a552-6489e2ea2758",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88877019-9c7a-4851-860d-0bada91b5324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After training, aggregate and visualize activation metrics\n",
    "plt.figure(figsize=(20, 4))\n",
    "legends = []\n",
    "\n",
    "for i, (name, data) in enumerate(activation_metrics.items()):\n",
    "    all_tensors = torch.cat(data['tensors'], dim=0)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    zero_percentage = (all_tensors == 0).float().mean() * 100\n",
    "    mean_value = all_tensors.mean().item()\n",
    "    std_value = all_tensors.std().item()\n",
    "    sparsity = (all_tensors != 0).float().mean() * 100\n",
    "    variance = all_tensors.var().item()\n",
    "    #saturated_percentage = (all_tensors.abs() > 0.97).float().mean() * 100\n",
    "\n",
    "    print(f'Layer {i} ({name}): mean: {mean_value:+.2f}, std: {std_value:.2f}, zeros: {zero_percentage:.2f}%, sparsity: {sparsity:.2f}%, variance: {variance:.2f}')#, saturated: {saturated_percentage:.2f}%')\n",
    "    \n",
    "    hy, hx = torch.histogram(all_tensors, density=True)\n",
    "    plt.plot(hx[:-1].detach().cpu(), hy.detach().cpu())\n",
    "    legends.append(f'Layer {i} ({name})')\n",
    "\n",
    "plt.legend(legends)\n",
    "plt.title('Activation Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddcd0b4-b167-4588-a030-febc7324aceb",
   "metadata": {},
   "source": [
    "# viz gradient distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85a0187-0941-46ee-9ff4-96bb62104e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.grad is not None:\n",
    "        print(f'{name} grad norm: {param.grad.data.norm(2).item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57534566-d872-4e09-b831-7c8858f4d966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# too long print of stats\n",
    "\n",
    "#viz gradient distributions\n",
    "#Visualize gradients after training\n",
    "plt.figure(figsize=(20, 4))\n",
    "legends = []\n",
    "for name, grad in gradients:\n",
    "    #print(f'{name}: mean: {grad.mean():+.2f}, std: {grad.std():.2e}')\n",
    "    hy, hx = torch.histogram(grad, density=True)\n",
    "    plt.plot(hx[:-1].detach().cpu(), hy.detach().cpu())\n",
    "    legends.append(name)\n",
    "plt.legend(legends)\n",
    "plt.title('Gradient Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32195d90-ce38-4da2-a312-49a857f04a3c",
   "metadata": {},
   "source": [
    "# Visualize gradients after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71829950-9608-4d4f-b7ca-fd24241ee54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "legends = []\n",
    "for i, p in enumerate(net.parameters()):\n",
    "    if p.grad is not None and p.ndim == 2:\n",
    "        t = p.grad\n",
    "        print(f'weight {tuple(p.shape)} | mean {t.mean():+.2f} | std {t.std():.2e} | grad:data ratio {t.std() / p.std():.2e}')\n",
    "        hy, hx = torch.histogram(t, density=True)\n",
    "        plt.plot(hx[:-1].detach().cpu(), hy.detach().cpu())\n",
    "        legends.append(f'{i} ({tuple(p.shape)})')\n",
    "plt.legend(legends)\n",
    "plt.title('Weight Gradient Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a4c38f-af81-4236-9b43-06dc8360948c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize histogram of activations\n",
    "plt.figure(figsize=(20,4)) # width and height of the plot\n",
    "legends = []\n",
    "for i,layer in enumerate(net): #not excluding the last layer since there is no softmax\n",
    "    if isinstance(layer, ReLU):\n",
    "        t = layer.out\n",
    "        print('layer %d (%10s): mean: %+.2f, std: %.2f, saturated: %.2f%%' %(i, layer.__class__.__name__, t.mean(), t.std(), (t.abs() > 0.97).float().mean()*100))\n",
    "        hy, hx = torch.histogram(t, density=True)\n",
    "        plt.plot(hx[:-1].detach(), hy.detach())\n",
    "        legends.append(f'layer {i} ({layer.__class__.__name__}')\n",
    "plt.legend(legends);\n",
    "plt.title('activation distribation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fe3de3-64d1-4af5-ad9a-dc4769e5f14d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e495e6e3-7801-4833-8178-c6ff7deabbb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f443d30-04c0-44a1-95cc-4d04b6dfdf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize histogram of gradient\n",
    "plt.figure(figsize=(20,4)) # width and height of the plot\n",
    "legends = []\n",
    "for i,p in enumerate(parameters): \n",
    "    if p.ndim == 2:\n",
    "        plt.plot([ud[j][i] for j in range(len(ud))])\n",
    "        legends.append('param %d' % i)\n",
    "plt.plot([0, len(ud)], [-3, -3], 'k') # those ratios should be ~1e-3, indicated on the plot with black         \n",
    "plt.legend(legends);\n",
    "plt.title('update to data raio distribation, LR setting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ef16b5-5953-4de8-a427-484e9e5579eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf08ad25-2856-4e31-863a-e4e9236fbc84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0ed3fde-5a90-40fc-997e-a3fa139ae9d2",
   "metadata": {},
   "source": [
    "# load from backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2782299-3a0c-457d-b580-c484b9cf82b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_model_from_checkpoint():\n",
    "#     checkpoint = torch.load('checkpoints/model_epoch_99.pt')\n",
    "\n",
    "#     net = Network()\n",
    "#     net.load_state_dict(checkpoint)\n",
    "#     net.eval()\n",
    "\n",
    "#     return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ce5e0f-b759-491b-9ca3-0a19f9b82d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "plt.plot(training_result[losses])\n",
    "plt.show()\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
